\documentclass{article}
\usepackage{graphicx}
\usepackage{float}
\usepackage{geometry}
\usepackage{tcolorbox}
\usepackage{amssymb} 
\usepackage{wasysym}
\usepackage{subcaption}
\usepackage{booktabs}
\usepackage{bm}
\usepackage{enumitem}
\usepackage{booktabs} 
\usepackage{hyperref}


\renewcommand{\labelenumi}{\Roman{enumi}.}
\definecolor{lightgray}{gray}{0.9} % Define lightgray color
\geometry{left=0.8in,right=0.8in,top=0.8in,bottom=1in}

\title{Experiment 1: Experimentation \& Evaluation 2023}
\author{Giorgio Bonetto \& Raffaele Perri}
\date{\today}

\begin{document}
\maketitle
In this comprehensive experiment assessing sorting algorithms for Bubble Inc.'s library, three algorithms (\texttt{BubbleSortPassPerItem}, \texttt{BubbleSortUntilNoChange}, \texttt{BubbleSortWhileNeeded}) were rigorously evaluated across diverse variables. The results consistently favored \texttt{BubbleSortWhileNeeded}, affirming its superiority in execution time. While variations occurred with different data types and array characteristics, the general trend supported the hypotheses. Notably, array dimension influenced execution time, but algorithm efficiency ranking remained consistent. Discrepancies were observed in specific scenarios, attributed to implementation details and environmental factors. Overall, the findings support selecting \texttt{BubbleSortWhileNeeded} for Bubble Inc.'s library, emphasizing its efficiency in diverse sorting scenarios.

\section{Introduction}
Bubble Inc., a software development company specializing in Java utilities, is faced with the crucial decision of selecting a sorting algorithm for inclusion in their upcoming library. The company has identified three candidate algorithms: BubbleSortPassPerItem, BubbleSortUntilNoChange, and BubbleSortWhileNeeded, all implementing the Sorter interface. The primary criterion for the selection process is performance, specifically the execution time required by each algorithm, with lower execution times being preferable.\\
To address this decision, we have designed a comprehensive experiment aimed at rigorously assessing the performance of the three sorting algorithms. While the choice of sorting algorithm is the primary independent variable, we also consider the manipulation of additional independent variables, such as the type of data in the array to be sorted and the array behaviour (random, sorted, partSorted, reverse, duplicates, noDuplicates, equal).\\
The experiment involves multiple repetitions of measurements to ensure statistical reliability. In this report, we present a detailed account of the experimental design, methodology, and the results obtained through careful analysis.\\
This experiment aims not only to contribute valuable insights to Bubble Inc.'s decision-making process but also to adhere to best practices in experimental design, ensuring transparency, reproducibility, and reliability in the assessment of sorting algorithm performance.


\begin{tcolorbox}[title=Hypotheses:, colback=white, colframe=black, arc=0pt, outer arc=0pt]
    \textbf{Hypothesis 1:} The \texttt{BubbleSortWhileNeeded} algorithm will exhibit significantly lower execution times compared to \texttt{BubbleSortPassPerItem} and \texttt{BubbleSortUntilNoChange} across various array types and dimensions.
    
    \textbf{Hypothesis 2:} The performance of sorting algorithms will vary based on the data type, with certain algorithms demonstrating better efficiency for specific data types.
    
    \textbf{Hypothesis 3:} The sorting algorithms will perform differently depending on the characteristics of the array, with variations in execution time for random, sorted, partially sorted, reverse sorted, arrays with duplicates, arrays with no duplicates, and arrays with equal elements.
    
    \textbf{Hypothesis 4:} There will be interactions between the sorting algorithm, data type, and array characteristics, influencing the overall performance of the sorting process.
    
    \textbf{Hypothesis 5:} As the array dimension increases, the execution time for each sorting algorithm will also increase, but the relative performance differences between algorithms will remain consistent.
\end{tcolorbox}


\section{Method}
In the following subsections, describe everything that a reader would need to replicate your experiment in all important details.
\subsection{Variables}
Explicitly identify the independent variable(s) (i.e., what you as the experimenter manipulate): 

    \begin{tcolorbox}[title=Independent Variable:, colback=white, colframe=black, arc=0pt, outer arc=0pt]
        \begin{itemize}
         \item[1.] \textbf{Sorting Algorithm (Algorithm Type):}
            \begin{itemize}
            \item BubbleSortPassPerItem
            \item BubbleSortUntilNoChange
            \item BubbleSortWhileNeeded
            \end{itemize}
        \item[2.] \textbf{Data Type (Type):}
            \begin{itemize}
            \item int
            \item Integer
            \item String
            \item double
            \item char
            \item byte
            \end{itemize}
        \item[3.] \textbf{Array Characteristics (Type of the Array):}
            \begin{itemize}
            \item random
            \item sorted
            \item partially sorted
            \item reverse sorted
            \item with duplicates
            \item with no duplicates
            \item with equal elements
            \end{itemize}
        \end{itemize}

    \end{tcolorbox}
Explicitly identify the dependent variable(s) (i.e., what you measure):\\

\begin{tcolorbox}[title=Dependent Variable:, colback=white, colframe=black, arc=0pt, outer arc=0pt]
    \begin{itemize}
        \item[1.] \textbf{Execution Time:}
        \begin{itemize}
            \item Measured in nanoseconds, capturing the time taken by each sorting algorithm to complete the sorting process.
        \end{itemize}
    \end{itemize}
\end{tcolorbox}

\subsection{Design}
Check off the characteristics of your experimental design:\\

\textbf{Type of Study} (check one):\\
\noindent
\begin{minipage}{0.4\textwidth}
    \fbox{\Square{} \textbf{Observational Study}}
\end{minipage}%
\begin{minipage}{0.4\textwidth}
    \fbox{\Square{} \textbf{Quasi-Experiment}}
\end{minipage}%
\begin{minipage}{0.2\textwidth}
    \fbox{\bm{\XBox{}} \textbf{Experiment}}
\end{minipage}\\\\
Conducted controlled experiments with intentional manipulation of variables to assess the performance of sorting algorithms.

In within-subjects (or 'repeated measures') designs, each participant is exposed to all of the conditions of the experiment.

In our experiment, we test each algorithm (\texttt{BubbleSortPassPerItem}, \texttt{BubbleSortUntilNoChange}, \texttt{BubbleSortWhileNeeded}) for each combination of the element type of the array with different characteristics of the array.

This means that each algorithm is tested for:

\begin{itemize}
    \item (\texttt{int}, [random, sorted, partially sorted, reverse sorted, with duplicates, with no duplicates, equal elements]),
    \item (\texttt{Integer}, [random, sorted, partially sorted, reverse sorted, with duplicates, with no duplicates, equal elements]),
    \item (\texttt{String}, [random, sorted, partially sorted, reverse sorted, with duplicates, with no duplicates, equal elements]),
    \item (\texttt{double}, [random, sorted, partially sorted, reverse sorted, with duplicates, with no duplicates, equal elements]),
    \item (\texttt{char}, [random, sorted, partially sorted, reverse sorted, with duplicates, with no duplicates, equal elements]),
    \item (\texttt{byte}, [random, sorted, partially sorted, reverse sorted, with duplicates, with no duplicates, equal elements]).
\end{itemize}

Furthermore, it has repeated measures because each of the previous array-type combinations is tested 150 times, for which the first 25 iterations are not counted as actual values but as warm-up values.
\\\\
\textbf{Number of Factors} (check one):\\
\noindent
\begin{minipage}{0.4\textwidth}
    \fbox{\Square\ \textbf{Single-Factor Design}}
\end{minipage}%
\begin{minipage}{0.4\textwidth}
    \fbox{\bm{\XBox{}} \textbf{Multi-Factor Design}}
\end{minipage}%
\begin{minipage}{0.0\textwidth}
    \fbox{\Square\ \textbf{Other}}
\end{minipage}\\\\
- Investigated the impact of multiple independent variables, including the sorting algorithm, data type, and array characteristics.
\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{./data/Group12.png}
    \caption{Multi-factor design}
\end{figure}

\subsection{Apparatus and Materials}
Describe in sufficient detail any relevant “props” that you used in your experiment. This could be the computer you used (exact model and specification), the software used (URL, version numbers), the way you measured, e.g., time (A stopwatch? A background process on the computer that got automatically triggered?). Omit needless detail (e.g., think whether details like the size of the table the laptop was placed on, or the hard disk size, might have affected your results or not).
\begin{itemize}
  \item \textbf{Sorting Algorithms:}
    \begin{itemize}
      \item Utilized three sorting algorithms:
        \begin{itemize}
          \item BubbleSortPassPerItem
          \item BubbleSortUntilNoChange
          \item BubbleSortWhileNeeded
        \end{itemize}
    \end{itemize}
     All algorithms implement the Sorter interface.

  \item \textbf{Data Types:}
    \begin{itemize}
      \item Evaluated various data types, including:
        \begin{itemize}
          \item int
          \item Integer
          \item String
          \item double
          \item char
          \item Byte
        \end{itemize}
    \end{itemize}

  \item \textbf{Array Characteristics:}
    \begin{itemize}
      \item Generated arrays with different characteristics:
        \begin{itemize}
          \item random
          \item sorted
          \item partSorted
          \item reverse
          \item duplicates
          \item noDuplicates
          \item equal
        \end{itemize}
    \end{itemize}

  \item \textbf{Measurement Tool:}
    \begin{itemize}
      \item Employed \texttt{System.nanoTime()} for precise measurement of execution time.
      \item Employed \texttt{System.currentTimeMillis()} for program measurements time. 
      \item Employed a stopwatch to measure again the time the program took.
    \end{itemize}
    
    \item \textbf{Machine used:}
    \begin{itemize}
      \item Hardware Model: \texttt{Dell Inc. Precision 5550}
      \item Firmware version: \texttt{1.24.1}
      \item Processor: \texttt{Intel® Core™ i7-10850H × 12}
      \item OS name: \texttt{Ubuntu 23.04}
      \item OS type: \texttt{64-bit}
      \item Kernel version: \texttt{Linux 6.2.0-36-generic}
    \end{itemize}
\end{itemize}



\subsection{Procedure}
Describe how you used your props and/or the participants to perform your actual experiment, i.e., how you actually carried out a single experimental run. What was done to the participants? What did they have to do? How long did each session take (unless this is an actual dependent variable)? If you did not have participants, explain, e.g., what software was started by whom in what order.
\begin{itemize}
  \item[1.] \textbf{Algorithm Implementation:}
    \begin{itemize}
      \item Implemented BubbleSortPassPerItem, BubbleSortUntilNoChange, and BubbleSortWhileNeeded algorithms.
    \end{itemize}

  \item[2.] \textbf{Array Generation:}
    \begin{itemize}
      \item Created arrays of varying types and characteristics using the \texttt{arrayGeneratorGeneral} method.
    \end{itemize}

  \item[3.] \textbf{Sorting Performance Analysis:}
    \begin{itemize}
      \item Repeated sorting processes 150 times for each combination of algorithm, data type, and array characteristics.
      \item Executed the sorting algorithms on generated arrays and recorded the execution time.
    \end{itemize}

  \item[4.] \textbf{Data Collection:}
    \begin{itemize}
      \item Collected and stored execution time data for analysis and reporting.
      \item Limited data recording to after the 25th iteration to ensure stabilized results.
    \end{itemize}

  \item[5.] \textbf{CSV Result Logging:}
    \begin{itemize}
      \item Logged the experiment results, including algorithm type, data type, array order, start time, end time, and elapsed time, into a CSV file (\texttt{results1000.csv/results10000.csv}).
    \end{itemize}
\end{itemize}
Times taken for the experiment:
    \begin{itemize}
     \item For array dimension of 1000: 20 minutes ($10:10 \rightarrow 10:30$)
     \item For array dimension of 10000: 2 hours ($10:37 \rightarrow 12:35$)
    \end{itemize}

\section{Results}
\subsection{Visual Overview}

Below, we present graphs representing the distribution of our data obtained through testing three different algorithms with various independent variables. The graphs are categorized into two groups: the first group represents data collected with an array dimension of 1000, while the second group represents data collected with an array dimension of 10000.\\

We have chosen to display the graphs using Boxen plots due to their ability to offer a detailed representation of the dataset's distribution. This choice is particularly advantageous for large datasets as Boxen plots provide enhanced visibility into distribution tails and varying data densities.\\
\begin{figure}[H]
    \centering
    \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{./data/comparison_algorithm_1000.png}
        \caption{Array dimension = 1000}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{./data/comparison_algorithm_10000.png}
        \caption{Array dimension = 10000}
    \end{subfigure}
    \caption{Graphs Algorithms Comparison}
\end{figure}

Here, we present graphs representing the distribution of our data obtained by testing three different algorithms. In both dimensions, the dense part of the data covers almost the same range, albeit on different scales. The array with a dimension of 1000 elements is on the scale of seconds multiplied by $10^{-2}$, while the array with a dimension of 10000 elements is on the scale of seconds.\\

From these two graphs, we can infer that, generally, regardless of the array type or dimension, the WhileNeededAlgorithm consistently emerges as the fastest.\\

Next, we explore how the algorithms perform with different types of arrays and different array orders.\\
\begin{figure}[H]
    \centering
    \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{./data/array_order_1000.png}
        \caption{Array dimension = 1000}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{./data/array_order_10000.png}
        \caption{Array dimension = 10000}
    \end{subfigure}
    \caption{Graph Array order Comparison between algorithms} 
\end{figure}

From these two graphs, we can observe the distinct sorting approaches employed by the three algorithms. For instance, when focusing on the array order "sorted," it becomes evident that the UntilNoChange and WhileNeeded algorithms outperform the PassPerItem algorithm. This suggests that, in many instances and depending on the array type, the former two algorithms efficiently traverse the array and return results swiftly. In contrast, the PassPerItem algorithm, with its need to compare each element and undergo a specified number of passes, experiences reduced efficiency.\\

Shifting our focus to the remaining array orders, we notice that they all closely align with the dense part of the first graph, which provides a general comparison of the three algorithms.\\

In the last two graphs, we illustrate the differences between various array types. Notably, the WhileNeededAlgorithm and UntilNoChange algorithms exhibit a broad distribution along the y-axis (elapsed time), likely influenced by the varying array orders. On the other hand, irrespective of array type and order, the other algorithm's data is more concentrated within a specific range.\\
\begin{figure}[H]
    \centering
    \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{./data/array_type_1000.png}
        \caption{Array dimension = 1000}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{./data/array_type_10000.png}
        \caption{Array dimension = 1000}
    \end{subfigure}
    \caption{Graph Array type Comparison between algorithms}
\end{figure}
\subsubsection{Standard Deviantion Calculation}

Below, you'll find the standard deviation calculations for the mean of the elapsed time among algorithms.\\

We opted to use standard deviation instead of absolute deviation because standard deviation is more sensitive to values that deviate significantly from the mean compared to absolute deviation.\\

The standard deviation is calculated using the following formula:
\[ \sigma = \sqrt{\frac{\sum_{i=1}^{n}(x_i - \bar{x})^2}{n-1}} \]

Below, we observe the differences in the standard deviation of the mean elapsed time among algorithms for array dimensions of both 1000 and 10000.\\


\begin{figure}[H]
    \centering
    \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{./data/std_algo_1000.png}
        \caption{Array dimension = 1000}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{./data/std_algo_10000.png}
        \caption{Array dimension = 10000}
    \end{subfigure}
    \caption{STD Mean of elapsed time between algorithms}
\end{figure}

Across both dimensions, the WhileNeededAlgorithm consistently demonstrates its efficiency, confirming it as the most efficient algorithm on average.

\begin{table}[h]
  \centering
  \caption{Standard Deviation of Elapsed Time for Each Algorithm}
  \begin{tabular}{lccc}
    \toprule
    Algorithm & STD-MEAN (10,000) & STD-MEAN (1,000) \\
    \midrule
    PassPerItem & $2.177038 \times 10^8$ & $1.940991 \times 10^6$ \\
    UntilNoChange & $3.194608 \times 10^8$ & $3.019103 \times 10^6$ \\
    WhileNeeded & $1.892941 \times 10^8$ & $1.847857 \times 10^6$ \\
    \bottomrule
  \end{tabular}
\end{table}
Here, we present the standard deviation of the elapsed time for each algorithm with various types of arrays and different array orders:\\
\begin{figure}[H]
  \centering
  \begin{subfigure}[b]{0.48\textwidth}
      \centering
      \includegraphics[width=\textwidth]{./data/std_order_array_1000.png}
      \caption{Array dimension = 1000}
  \end{subfigure}
  \hfill
  \begin{subfigure}[b]{0.48\textwidth}
      \centering
      \includegraphics[width=\textwidth]{./data/std_order_array_10000.png}
      \caption{Array dimension = 10000}
  \end{subfigure}
  \caption{STD Mean of elapsed time of Array Order between algorithms}
\end{figure}


\begin{figure}[H]
    \centering
    \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{./data/std_type_array_1000.png}
        \caption{Array dimension = 1000}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{./data/std_type_array_10000.png}
        \caption{Array dimension = 10000}
    \end{subfigure}
    \caption{STD Mean of elapsed time of Array Type between algorithms}
\end{figure}


\subsection{Descriptive Statistics}
\begin{table}[H]
    \centering
    \label{tab:algorithm_metrics}
    \begin{tabular}{|c|c|c|c|c|c|c|c|c|}
        \toprule
        \textbf{Algorithm} & \textbf{Array Type} & \textbf{Array Order} & \textbf{min} & \textbf{Q1} & \textbf{Median} & \textbf{Q3} & \textbf{max} \\
        \midrule
        & Byte & duplicates & 3646238.0 & 3756575.0 & 3808821.0 & 3867342.0 & 8357071.0 \\
        & Byte & equal & 2935979.0 & 3019169.0 & 3087391.0 & 3157950.0 & 5288457.0 \\
        & Byte & noDuplicates & 3788220.0 & 3856847.0 & 3898842.0 & 3977115.0 & 6742442.0 \\
        & Byte & partSorted & 3727686.0 & 3882174.0 & 4527043.0 & 4614871.0 & 7998889.0 \\
        & Byte & random & 4060434.0 & 4570201.0 & 4614511.0 & 4728887.0 & 8119986.0 \\
        & Byte & reverse & 3954729.0 & 4323938.0 & 4357431.0 & 4433003.0 & 6930753.0 \\
        & Byte & sorted & 3598158.0 & 3656735.0 & 3709855.0 & 3907112.0 & 6766076.0 \\
       
        & Character & duplicates & 3740947.0 & 3846082.0 & 3887237.0 & 3954177.0 & 5698293.0 \\
        & Character & equal & 2893077.0 & 3569756.0 & 3615591.0 & 3720252.0 & 6190770.0 \\
        & Character & noDuplicates & 3598108.0 & 3842692.0 & 3889248.0 & 3961125.0 & 5906079.0 \\
        & Character & partSorted & 3390725.0 & 3533691.0 & 3596476.0 & 3645536.0 & 6174360.0 \\
        & Character & random & 3792844.0 & 3858078.0 & 3991903.0 & 4112282.0 & 7165440.0 \\
        & Character & reverse & 3928958.0 & 4074894.0 & 4199993.0 & 4795254.0 & 6346055.0 \\
        & Character & sorted & 3413329.0 & 3592020.0 & 3629016.0 & 3737123.0 & 6490337.0 \\
        
        & Double & duplicates & 3891059.0 & 4564416.0 & 4708132.0 & 4800219.0 & 7886275.0 \\
        & Double & equal & 4291813.0 & 4516993.0 & 4562359.0 & 4681925.0 & 7910216.0 \\
        & Double & noDuplicates & 3873884.0 & 4000343.0 & 4045788.0 & 4152261.0 & 6001258.0 \\
        & Double & partSorted & 3655190.0 & 4378000.0 & 4419958.0 & 4468273.0 & 7704964.0 \\
        & Double & random & 3761499.0 & 3938283.0 & 4008754.0 & 4116739.0 & 6340284.0 \\
        & Double & reverse & 4016233.0 & 4189450.0 & 4243337.0 & 4314153.0 & 5774845.0 \\
        & Double & sorted & 2994578.0 & 3128397.0 & 3151628.0 & 3215041.0 & 5658673.0 \\
        PassPerItem
        & Integer & duplicates & 3463755.0 & 3540117.0 & 3598020.0 & 3676245.0 & 4797625.0 \\
        & Integer & equal & 2577646.0 & 2748983.0 & 2819274.0 & 2884196.0 & 4147536.0 \\
        & Integer & noDuplicates & 3122117.0 & 3297333.0 & 3348221.0 & 3437558.0 & 5077096.0 \\
        & Integer & partSorted & 2919993.0 & 3014345.0 & 3079822.0 & 3166664.0 & 4806705.0 \\
        & Integer & random & 4274735.0 & 4441081.0 & 4497042.0 & 4597413.0 & 6427093.0 \\
        & Integer & reverse & 3329975.0 & 3487040.0 & 3553294.0 & 3642864.0 & 6333695.0 \\
        & Integer & sorted & 2591549.0 & 3073455.0 & 3243781.0 & 3312198.0 & 5477617.0 \\
        
        & String & duplicates & 6633237.0 & 8086784.0 & 8239239.0 & 8544916.0 & 12653117.0 \\
        & String & equal & 2949728.0 & 3155401.0 & 3213564.0 & 3304831.0 & 5930131.0 \\
        & String & noDuplicates & 9318118.0 & 9533921.0 & 10487439.0 & 11103731.0 & 14899991.0 \\
        & String & partSorted & 8450381.0 & 8746620.0 & 8870049.0 & 10176884.0 & 13913313.0 \\
        & String & random & 6499265.0 & 6923228.0 & 7118070.0 & 8018541.0 & 12726856.0 \\
        & String & reverse & 7797864.0 & 7985778.0 & 8115074.0 & 8398284.0 & 10895706.0 \\
        & String & sorted & 8640260.0 & 8914419.0 & 9091600.0 & 9290393.0 & 12106259.0 \\
        
        & int & duplicates & 3343333.0 & 3482982.0 & 3533921.0 & 3596568.0 & 5805610.0 \\
        & int & equal & 2580467.0 & 2763506.0 & 2829700.0 & 2927601.0 & 4829911.0 \\
        & int & noDuplicates & 3118135.0 & 3272580.0 & 3329326.0 & 3447653.0 & 5547094.0 \\
        & int & partSorted & 3297450.0 & 3597617.0 & 3640150.0 & 3727489.0 & 5580725.0 \\
        & int & random & 5144896.0 & 5269400.0 & 5344085.0 & 5457277.0 & 7180828.0 \\
        & int & reverse & 3331252.0 & 3462131.0 & 3529574.0 & 3639483.0 & 5709480.0 \\
        & int & sorted & 2903662.0 & 3225032.0 & 3281266.0 & 3346823.0 & 5589207.0 \\
        \bottomrule
    \end{tabular}
    \caption{Algorithm Performance Metrics for PassPerItem}
\end{table}
\begin{table}[H]
    \centering
    \label{tab:untilnochange_metrics}
    \begin{tabular}{|c|c|c|c|c|c|c|c|c|}
        \toprule
        \textbf{Algorithm} & \textbf{Array Type} & \textbf{Array Order} & \textbf{min} & \textbf{Q1} & \textbf{Median} & \textbf{Q3} & \textbf{max} \\
        \midrule
        & Byte & duplicates & 5215359.0 & 5426623.0 & 5498350.0 & 5635537.0 & 8687405.0 \\
        & Byte & equal & 5001.0 & 5370.0 & 5719.0 & 8353.0 & 25859.0 \\
        & Byte & noDuplicates & 5592581.0 & 5881570.0 & 5975926.0 & 6068955.0 & 8525470.0 \\
        & Byte & partSorted & 5356346.0 & 5764532.0 & 6484797.0 & 6787677.0 & 11309064.0 \\
        & Byte & random & 6314645.0 & 7014826.0 & 7111694.0 & 7281527.0 & 12352740.0 \\
        & Byte & reverse & 5386158.0 & 5838850.0 & 5880371.0 & 5968197.0 & 8837784.0 \\
        & Byte & sorted & 4973581.0 & 5049731.0 & 5154270.0 & 5418453.0 & 9501319.0 \\
        
        & Character & duplicates & 5380184.0 & 5718432.0 & 5805834.0 & 5888586.0 & 9927778.0 \\
        & Character & equal & 4984.0 & 6207.0 & 6542.0 & 9635.0 & 25899.0 \\
        & Character & noDuplicates & 5525239.0 & 5716642.0 & 5804618.0 & 5901497.0 & 9412445.0 \\
        & Character & partSorted & 5040773.0 & 5401725.0 & 5513847.0 & 5647164.0 & 8130289.0 \\
        & Character & random & 5516999.0 & 5787208.0 & 5893001.0 & 6095069.0 & 9401375.0 \\
        & Character & reverse & 5796250.0 & 5916038.0 & 6073921.0 & 6941697.0 & 8287703.0 \\
        & Character & sorted & 6000.0 & 6378.0 & 6676.0 & 9595.0 & 15193.0 \\
        
        & Double & duplicates & 4202655.0 & 5189774.0 & 5401865.0 & 5525006.0 & 7689250.0 \\
        & Double & equal & 4859.0 & 5410.0 & 5645.0 & 5977.0 & 22616.0 \\
        & Double & noDuplicates & 4376720.0 & 4553075.0 & 4626721.0 & 4732249.0 & 7538549.0 \\
        & Double & partSorted & 3984865.0 & 4880262.0 & 4976631.0 & 5105775.0 & 8221830.0 \\
        & Double & random & 4239250.0 & 4509314.0 & 4604403.0 & 4736491.0 & 7325297.0 \\
        & Double & reverse & 4700677.0 & 4821353.0 & 4867876.0 & 4974744.0 & 6470144.0 \\
        & Double & sorted & 3824.0 & 4270.0 & 4774.0 & 6409.0 & 26539.0 \\
        UntilNoChange
        & Integer & duplicates & 2500193.0 & 2680410.0 & 2740821.0 & 2833826.0 & 4790417.0 \\
        & Integer & equal & 1921.0 & 2155.0 & 2502.0 & 3209.0 & 23405.0 \\
        & Integer & noDuplicates & 2409786.0 & 2518111.0 & 2586739.0 & 2699469.0 & 4524521.0 \\
        & Integer & partSorted & 2062780.0 & 2225946.0 & 2293881.0 & 2380345.0 & 4146141.0 \\
        & Integer & random & 3820289.0 & 4092529.0 & 4169135.0 & 4229902.0 & 6172818.0 \\
        & Integer & reverse & 2758603.0 & 2841655.0 & 2913743.0 & 3008567.0 & 5233527.0 \\
        & Integer & sorted & 1979.0 & 2505.0 & 2908.0 & 3758.0 & 31383.0 \\
        
        & String & duplicates & 6416213.0 & 8015924.0 & 8253134.0 & 8469550.0 & 12367124.0 \\
        & String & equal & 3268.0 & 3645.0 & 4342.0 & 5790.0 & 19151.0 \\
        & String & noDuplicates & 9170059.0 & 9822109.0 & 10284872.0 & 11499502.0 & 15254867.0 \\
        & String & partSorted & 8258231.0 & 8918542.0 & 9123824.0 & 10404024.0 & 15786142.0 \\
        & String & random & 6660782.0 & 6911349.0 & 7147949.0 & 7921691.0 & 11900423.0 \\
        & String & reverse & 8010615.0 & 8177631.0 & 8286995.0 & 8522808.0 & 13240213.0 \\
        & String & sorted & 896517.0 & 958599.0 & 990992.0 & 1048618.0 & 1668638.0 \\
        
        & int & duplicates & 2502082.0 & 2618653.0 & 2672308.0 & 2755727.0 & 3633136.0 \\
        & int & equal & 1944.0 & 2200.0 & 2443.0 & 3116.0 & 5192.0 \\
        & int & noDuplicates & 2384768.0 & 2522486.0 & 2591091.0 & 2695739.0 & 4702782.0 \\
        & int & partSorted & 2398022.0 & 2634232.0 & 2694768.0 & 2778662.0 & 4822703.0 \\
        & int & random & 4629902.0 & 4818649.0 & 4905973.0 & 5044764.0 & 7465709.0 \\
        & int & reverse & 2712334.0 & 2821741.0 & 2881678.0 & 2954795.0 & 4803311.0 \\
        & int & sorted & 2364.0 & 2586.0 & 2801.0 & 3281.0 & 5411.0 \\
        \bottomrule
    \end{tabular}
    \caption{Algorithm Performance Metrics for UntilNoChange}
\end{table}

\begin{table}[H]
    \centering
    \label{tab:untilnochange_metrics}
    \begin{tabular}{|c|c|c|c|c|c|c|c|c|}
        \toprule
        \textbf{Algorithm} & \textbf{Array Type} & \textbf{Array Order} & \textbf{min} & \textbf{Q1} & \textbf{Median} & \textbf{Q3} & \textbf{max} \\
        \midrule
        & Byte & duplicates & 3554805.0 & 3647981.0 & 3705361.0 & 3808088.0 & 5570046.0 \\
        & Byte & equal & 4857.0 & 4981.0 & 7658.0 & 8267.0 & 24460.0 \\
        & Byte & noDuplicates & 3691380.0 & 3782508.0 & 3834119.0 & 3906792.0 & 6222995.0 \\
        & Byte & partSorted & 3485835.0 & 3587534.0 & 4159977.0 & 4244896.0 & 7967867.0 \\
        & Byte & random & 3978520.0 & 4449542.0 & 4498133.0 & 4587372.0 & 6938977.0 \\
        & Byte & reverse & 3144353.0 & 3367681.0 & 3391539.0 & 3468161.0 & 5867272.0 \\
        & Byte & sorted & 2929197.0 & 2991186.0 & 3059666.0 & 3263906.0 & 4934011.0 \\
        
        & Character & duplicates & 3505261.0 & 3616613.0 & 3655093.0 & 3729796.0 & 6001368.0 \\
        & Character & equal & 4936.0 & 5943.0 & 8540.0 & 9792.0 & 33465.0 \\
        & Character & noDuplicates & 3477688.0 & 3615958.0 & 3664275.0 & 3756953.0 & 5556636.0 \\
        & Character & partSorted & 3028176.0 & 3138755.0 & 3191658.0 & 3252115.0 & 5422040.0 \\
        & Character & random & 3454506.0 & 3592135.0 & 3652573.0 & 3763977.0 & 6246366.0 \\
        & Character & reverse & 3457301.0 & 3565772.0 & 3691675.0 & 4169464.0 & 5203627.0 \\
        & Character & sorted & 5743.0 & 6019.0 & 6171.0 & 9616.0 & 11633.0 \\
        
        & Double & duplicates & 2654100.0 & 3200206.0 & 3249071.0 & 3332622.0 & 4823338.0 \\
        & Double & equal & 4617.0 & 5168.0 & 6827.0 & 7893.0 & 36000.0 \\
        & Double & noDuplicates & 2648955.0 & 2736471.0 & 2780851.0 & 2854926.0 & 3940499.0 \\
        & Double & partSorted & 2384929.0 & 2831043.0 & 2879706.0 & 2929652.0 & 4445295.0 \\
        & Double & random & 2627232.0 & 2717131.0 & 2765478.0 & 2843572.0 & 4586852.0 \\
        & Double & reverse & 2856751.0 & 2936441.0 & 2975444.0 & 3069487.0 & 4633380.0 \\
        & Double & sorted & 3562.0 & 3824.0 & 4089.0 & 6436.0 & 33992.0 \\
        WhileNeeded
        & Integer & duplicates & 1816936.0 & 1885592.0 & 1918774.0 & 1971106.0 & 3196126.0 \\
        & Integer & equal & 1676.0 & 1815.0 & 2290.0 & 2932.0 & 3666.0 \\
        & Integer & noDuplicates & 1615914.0 & 1670172.0 & 1713811.0 & 1814979.0 & 2960582.0 \\
        & Integer & partSorted & 1221295.0 & 1290361.0 & 1324990.0 & 1375905.0 & 2015366.0 \\
        & Integer & random & 2738700.0 & 2865570.0 & 2897588.0 & 2996808.0 & 4154920.0 \\
        & Integer & reverse & 2071300.0 & 2170567.0 & 2207418.0 & 2287419.0 & 3881794.0 \\
        & Integer & sorted & 1709.0 & 2096.0 & 2212.0 & 3311.0 & 4709.0 \\
        
        & String & duplicates & 4205590.0 & 5179006.0 & 5260552.0 & 5377807.0 & 6850935.0 \\
        & String & equal & 3486.0 & 3829.0 & 5668.0 & 6879.0 & 34439.0 \\
        & String & noDuplicates & 5934605.0 & 6150323.0 & 6596568.0 & 7151407.0 & 8550499.0 \\
        & String & partSorted & 5217055.0 & 5396484.0 & 5496800.0 & 6275181.0 & 11547706.0 \\
        & String & random & 4203543.0 & 4414065.0 & 4535138.0 & 5141019.0 & 7119076.0 \\
        & String & reverse & 4381985.0 & 4484555.0 & 4528680.0 & 4625965.0 & 7375641.0 \\
        & String & sorted & 502962.0 & 540318.0 & 566102.0 & 627231.0 & 928117.0 \\
        
        & int & duplicates & 1741590.0 & 1853781.0 & 1884699.0 & 1945793.0 & 3296010.0 \\
        & int & equal & 1632.0 & 1901.0 & 2471.0 & 2816.0 & 22645.0 \\
        & int & noDuplicates & 1608437.0 & 1689313.0 & 1724352.0 & 1796194.0 & 2902586.0 \\
        & int & partSorted & 1384650.0 & 1530240.0 & 1568759.0 & 1625405.0 & 2734052.0 \\
        & int & random & 3222701.0 & 3360729.0 & 3391654.0 & 3486036.0 & 5055648.0 \\
        & int & reverse & 2059251.0 & 2154267.0 & 2199403.0 & 2271801.0 & 3904261.0 \\
        & int & sorted & 1941.0 & 2164.0 & 2261.0 & 3341.0 & 4968.0 \\
        \bottomrule
    \end{tabular}
    \caption{Algorithm Performance Metrics for WhileNeeded}
\end{table}

\section{Discussion}
\subsection{Compare Hypothesis to Results}
\begin{tcolorbox}[title=Experiment Overview, colback=white, colframe=black, arc=0pt, outer arc=0pt]
    In the conducted experiment, the performance of three sorting algorithms—\texttt{BubbleSortPassPerItem}, \texttt{BubbleSortUntilNoChange}, and \texttt{BubbleSortWhileNeeded}—was rigorously assessed across various independent variables, including sorting algorithm type, data type, array characteristics, and array dimension. The primary dependent variable was the execution time, measured in nanoseconds.
\end{tcolorbox}

\subsection*{Main Results}
\begin{itemize}
 \item \textbf{Algorithm Comparison}:
        \begin{itemize}
          \item \texttt{BubbleSortWhileNeeded} consistently demonstrated the lowest execution times across different array types and dimensions.
          \item \texttt{BubbleSortUntilNoChange} also exhibited competitive performance, often outperforming \texttt{BubbleSortPassPerItem}.
        \end{itemize}
\end{itemize}

\begin{itemize}
 \item \textbf{Data Type Influence}:
        \begin{itemize}
          \item While there were variations, the performance across data types remained consistent with \texttt{BubbleSortWhileNeeded} being the most efficient in most cases.
        \end{itemize}
\end{itemize}


\begin{itemize}
 \item \textbf{Array Characteristics Impact}:
        \begin{itemize}
          \item Array characteristics, such as order and type, influenced algorithm performance.
          \item \texttt{BubbleSortWhileNeeded} and \texttt{BubbleSortUntilNoChange} generally outperformed \texttt{BubbleSortPassPerItem}, especially in sorted array orders.
        \end{itemize}
\end{itemize}

\begin{itemize}
 \item \textbf{Array Dimension Effect}:
        \begin{itemize}
          \item As expected, execution times increased with the array dimension, but the relative performance differences between algorithms remained consistent.
        \end{itemize}
\end{itemize}

\subsection*{Support for Research Hypotheses}

\begin{itemize}
    \item \textbf{Hypothesis 1 (Algorithm Type):} Supported.\\ \texttt{BubbleSortWhileNeeded} consistently demonstrated the fastest execution times, aligning with the hypothesis.
    \item \textbf{Hypothesis 2 (Data Type):} Partially supported. \\
    While there were variations, the overall trend of \texttt{BubbleSortWhileNeeded}'s efficiency held across different data types.
    \item \textbf{Hypothesis 3 (Array Characteristics):} Supported. \\
    The experiment demonstrated that array characteristics significantly impact sorting algorithm performance.
    \item \textbf{Hypothesis 4 (Interactions):} Supported. \\
    Interactions between algorithm type, data type, and array characteristics were evident in influencing sorting performance.
    \item \textbf{Hypothesis 5 (Array Dimension):} Supported. \\
    As expected, execution times increased with array dimension, but the ranking of algorithm efficiency remained consistent.
\end{itemize}


\subsection*{Discrepancies}

\begin{itemize}[label=$\bullet$]
    \item While the experiment largely supported the hypotheses, there were instances where the performance differences between algorithms were less pronounced, especially in certain array types.
    \item Variability in data types and array characteristics may have contributed to instances where the expected trends were not consistently observed.
\end{itemize}

\subsection*{Speculations on Discrepancies}

\begin{itemize}[label=$\bullet$]
    \item The specific implementation details of the sorting algorithms and the characteristics of the Java runtime environment on the testing machine could also contribute to variations.
\end{itemize}

\begin{tcolorbox}[title=Conclusion, colback=white, colframe=black, arc=0pt, outer arc=0pt]
    Overall, the experiment's results provide valuable insights into the performance of sorting algorithms, supporting the selection of \texttt{BubbleSortWhileNeeded} as a preferable choice for Bubble Inc.'s upcoming library, especially in scenarios where quick and efficient sorting is crucial.
\end{tcolorbox}


\subsection{Limitations and Threats to Validity}
The enviroment and conditions for the experiment are expressed and explained in the sections above.
However, these are not the absolute conditions for the experiment.
The order of tested algorithms and array types could introduce discrepancies.
A way to avoid this could be done by using randomization techniques so that each algorithm is tested in random order.
Furthermore, one potential source of measurement issues arises from the lack of isolation of the testing process. Factors such as uncontrolled background processes or varying system loads during the tests could introduce errors in the measurement of elapsed time. It is important to acknowledge that, at present, the testing process has not been sufficiently isolated, potentially impacting the accuracy and reliability of the measured results. To address this, future iterations of the experiment should aim to minimize external influences on the testing environment, thereby enhancing the internal validity of the measurements.

Also, the experiment covered a range of data types and array characteristics, but the generalizability to all possible combinations is limited.
Additionally, the machine on which the tests are conducted can influence the results. To address this, the experiment has been repeated multiple times on the same machine, establishing a level of confidence that the results are consistent on that specific hardware configuration. However, it cannot be assumed that replicating the experiment on different machines, particularly those running different operating systems like Windows or Mac, would yield the same results.
The impact of array dimension on algorithm performance may vary based on specific characteristics. In this case, the experiment considered two array dimensions (1000 and 10000).

\section{Appendix}
\subsection{Materials}
\textbf{Book: } \textit{How to Design and Report Experiments} by Andy Field and Graham J Hole\\
\textbf{Software: } \textit{Google Colab} for statistical analysis, \textit{Visual Studio Code}, \textit{Figma} for multi-factor design\\
\textbf{Programming Language: } \textit{Java} for implementation of sorting algorithms and for running the tests\\
\textbf{Machine: } \textit {Dell Inc. Precision 5550 }
\subsection{Reproduction Package}
Before, during, and after the experiment you collected all kinds of data. Don't ever throw such data away! Any plots, tables, summaries, and statistics provided in this report should be recreatable from the raw data you have.

If you only collected a small amount of data, put it in this Appendix right here.

If you collected data in forms that are better kept in separate files, then zip up those files, and submit them as a "reproduction package" supporting this report.

\subsection*{{Github repo: (\url{https://github.com/Bonett0/experiment-01})}}




\end{document}
